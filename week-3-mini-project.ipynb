{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mini-Project: Histopathologic Cancer Detection\n\nThis notebook provides a solution for the Histopathologic Cancer Detection Kaggle competition, developed as part of the Deep Learning course at CU Boulder. It includes problem explanation, exploratory data analysis (EDA), data preprocessing, model building with hyperparameter tuning, results analysis, and a conclusion.\n\n## 1. Project Explanation\nThe goal is to classify histopathologic images as cancerous (label=1) or non-cancerous (label=0) based on a 32x32 pixel region in 96x96 pixel images. The dataset contains over 220,000 training images and 57,000 test images, each in .tif format. The task is a binary classification problem, requiring a deep learning model to detect cancerous regions accurately.\n\n## 2. Data Description\nThe dataset includes:\n- **Training labels**: A CSV file (`train_labels.csv`) with image IDs and binary labels (0 or 1).\n- **Training images**: 96x96 pixel .tif images in the `train` directory.\n- **Test images**: 96x96 pixel .tif images in the `test` directory, without labels.\n- **Size**: ~220,000 training images, ~57,000 test images.\n- **Structure**: Images are RGB, and labels indicate the presence (1) or absence (0) of cancer in the central 32x32 region.\n\n## 3. Imports and exploratory Data Analysis (EDA)","metadata":{"_uuid":"3510662e-1932-40d2-87cf-6168825e3449","_cell_guid":"f990a051-6734-4938-a05f-05f0a954fffb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport torch\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Define paths\ndata_dir = '/kaggle/input/histopathologic-cancer-detection/'\ntrain_labels_path = os.path.join(data_dir, 'train_labels.csv')\ntrain_images_dir = os.path.join(data_dir, 'train')\ntest_images_dir = os.path.join(data_dir, 'test')\n\n# Load labels\ntrain_labels_df = pd.read_csv(train_labels_path)\n\n# Basic data description\nprint(f\"Training labels shape: {train_labels_df.shape}\")\nprint(\"\\nFirst 5 rows of training labels:\")\nprint(train_labels_df.head().to_markdown(index=False))\nprint(\"\\nMissing values in training labels:\")\nprint(train_labels_df.isnull().sum())\n\n# Check for duplicates\nprint(\"\\nDuplicate rows in training labels:\")\nprint(train_labels_df[train_labels_df.duplicated(keep=False)])\n\n# Class distribution\nclass_counts = train_labels_df['label'].value_counts()\nprint(\"\\nClass distribution:\")\nprint(class_counts)\n\n# Visualize class distribution\nplt.figure(figsize=(8, 6))\nsns.countplot(x='label', data=train_labels_df)\nplt.title('Class Distribution (0: Non-Cancerous, 1: Cancerous)')\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()\n\n# Display sample images\ndef display_sample_images(df, image_dir, num_samples=3):\n    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples*4, 8))\n    for i, label in enumerate([0, 1]):\n        label_df = df[df['label'] == label].sample(num_samples, random_state=42)\n        for j, row in enumerate(label_df.itertuples()):\n            img_path = os.path.join(image_dir, f'{row.id}.tif')\n            img = Image.open(img_path)\n            axes[i, j].imshow(img)\n            axes[i, j].set_title(f'Label: {label}')\n            axes[i, j].axis('off')\n    plt.suptitle('Sample Images (Top: Non-Cancerous, Bottom: Cancerous)')\n    plt.show()\n\ndisplay_sample_images(train_labels_df, train_images_dir)\n\n# Image statistics\nsample_image = Image.open(os.path.join(train_images_dir, f'{train_labels_df[\"id\"].iloc[0]}.tif'))\nprint(f\"\\nSample image dimensions: {sample_image.size}\")\nprint(f\"Sample image mode: {sample_image.mode}\")\n\n# Pixel intensity distribution\ndef plot_pixel_intensity(image_dir, sample_ids, title):\n    plt.figure(figsize=(10, 6))\n    for img_id in sample_ids[:3]:\n        img_path = os.path.join(image_dir, f'{img_id}.tif')\n        img = np.array(Image.open(img_path))\n        plt.hist(img.flatten(), bins=50, alpha=0.5, label=f'Image {img_id[:5]}')\n    plt.title(title)\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('Frequency')\n    plt.legend()\n    plt.show()\n\nsample_ids = train_labels_df['id'].sample(3, random_state=42).values\nplot_pixel_intensity(train_images_dir, sample_ids, 'Pixel Intensity Distribution')","metadata":{"_uuid":"b906810b-0300-4ac7-82d6-f91967efa9df","_cell_guid":"2235fc7c-5973-455c-afe3-b7d948b6125c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-26T08:55:50.160313Z","iopub.execute_input":"2025-05-26T08:55:50.160670Z","iopub.status.idle":"2025-05-26T08:55:51.992570Z","shell.execute_reply.started":"2025-05-26T08:55:50.160638Z","shell.execute_reply":"2025-05-26T08:55:51.991451Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 4. Data Preprocessing & Analysis Plan\nBased on EDA:\n- **Class imbalance**: ~60% non-cancerous, ~40% cancerous. Use class weights in loss function.\n- **Preprocessing**: Normalize images using mean and std from ImageNet. Apply data augmentation (flips, rotations) to improve generalization.\n- **Plan**: Use a CNN with iterative hyperparameter tuning (learning rate, batch size, architecture depth). Evaluate using validation accuracy and AUC.","metadata":{"_uuid":"717bd3a4-6ed2-4d9d-92e7-407bb50ea463","_cell_guid":"248cf96e-c7c7-410b-abf0-71e02888f55d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Enhanced data transformations\ntrain_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Custom dataset\nclass CancerDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, image_dir, transform=None):\n        self.dataframe = dataframe\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.iloc[idx, 0]\n        label = self.dataframe.iloc[idx, 1] if 'label' in self.dataframe.columns else 0\n        img_path = os.path.join(self.image_dir, f'{img_name}.tif')\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Split dataset\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(train_labels_df, test_size=0.2, stratify=train_labels_df['label'], random_state=42)\n\n# Create datasets and loaders\ntrain_dataset = CancerDataset(train_df, train_images_dir, transform=train_transforms)\nval_dataset = CancerDataset(val_df, train_images_dir, transform=val_transforms)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)","metadata":{"_uuid":"e13baeba-c3e0-46c2-bc94-035f3dd74bce","_cell_guid":"8cd3a906-3539-4558-aa24-aaba0d9bde4c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-26T08:55:58.430426Z","iopub.execute_input":"2025-05-26T08:55:58.430781Z","iopub.status.idle":"2025-05-26T08:55:58.542558Z","shell.execute_reply.started":"2025-05-26T08:55:58.430758Z","shell.execute_reply":"2025-05-26T08:55:58.541685Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 5. Model Architecture\nI use a deeper CNN with batch normalization and dropout for regularization. The architecture is inspired by VGG-like models but tailored for 96x96 images.","metadata":{"_uuid":"d7819464-5ee3-405e-b175-3137171ea644","_cell_guid":"4f0864d9-bb88-48ed-bfab-6ac31ae5fdd6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass DeepCNN(nn.Module):\n    def __init__(self, num_filters=32, dropout_rate=0.5):\n        super(DeepCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, num_filters, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_filters),\n            nn.ReLU(),\n            nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_filters),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(num_filters, num_filters*2, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_filters*2),\n            nn.ReLU(),\n            nn.Conv2d(num_filters*2, num_filters*2, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_filters*2),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(num_filters*2, num_filters*4, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_filters*4),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n        )\n        with torch.no_grad():\n            dummy_input = torch.zeros(1, 3, 96, 96)\n            dummy_output = self.features(dummy_input)\n            self.flattened_size = dummy_output.view(1, -1).size(1)\n        self.classifier = nn.Sequential(\n            nn.Linear(self.flattened_size, 512),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(512, 2)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x","metadata":{"_uuid":"6f3341b1-d9b6-4885-95da-540cbeb1e947","_cell_guid":"adba8ba0-da5f-4491-89c9-9b54f450b3c5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-26T08:56:01.779639Z","iopub.execute_input":"2025-05-26T08:56:01.779968Z","iopub.status.idle":"2025-05-26T08:56:01.789890Z","shell.execute_reply.started":"2025-05-26T08:56:01.779946Z","shell.execute_reply":"2025-05-26T08:56:01.788954Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameter tuning\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\n\ndef train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10):\n    train_losses, val_losses, val_accuracies, val_aucs = [], [], [], []\n    best_auc, best_model = 0.0, None\n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        train_loss = running_loss / len(train_loader)\n        train_losses.append(train_loss)\n\n        # Validation\n        model.eval()\n        val_loss, correct, total, all_preds, all_labels = 0.0, 0, 0, [], []\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n                all_preds.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n        val_loss /= len(val_loader)\n        val_accuracy = 100 * correct / total\n        val_auc = roc_auc_score(all_labels, all_preds)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n        val_aucs.append(val_auc)\n        scheduler.step(val_loss)\n\n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Val AUC: {val_auc:.4f}\")\n\n        if val_auc > best_auc:\n            best_auc = val_auc\n            best_model = model.state_dict()\n\n    return train_losses, val_losses, val_accuracies, val_aucs, best_model","metadata":{"_uuid":"e81b1c0c-6747-4fdf-8c0e-2414f1925e0c","_cell_guid":"645d5d08-d65a-4d13-8bbf-e47e3dd710de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-26T08:56:03.751546Z","iopub.execute_input":"2025-05-26T08:56:03.751860Z","iopub.status.idle":"2025-05-26T08:56:03.762948Z","shell.execute_reply.started":"2025-05-26T08:56:03.751838Z","shell.execute_reply":"2025-05-26T08:56:03.762043Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Try different hyperparameters\nhyperparams = [\n    {'num_filters': 32, 'dropout_rate': 0.5, 'lr': 0.001, 'batch_size': 64},\n    {'num_filters': 64, 'dropout_rate': 0.3, 'lr': 0.0005, 'batch_size': 32},\n]\n\nresults = []\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass_weights = torch.tensor([1.0, class_counts[0] / class_counts[1]], dtype=torch.float).to(device)\n\nfor params in hyperparams:\n    print(f\"\\nTraining with params: {params}\")\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True, num_workers=4)\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=4)\n    model = DeepCNN(num_filters=params['num_filters'], dropout_rate=params['dropout_rate']).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    train_losses, val_losses, val_accuracies, val_aucs, best_model = train_and_evaluate(\n        model, train_loader, val_loader, criterion, optimizer, scheduler, device\n    )\n    results.append({\n        'params': params,\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_accuracies': val_accuracies,\n        'val_aucs': val_aucs,\n        'best_model': best_model\n    })","metadata":{"_uuid":"8f9da96e-e7a8-41b7-92f1-061be1352dd2","_cell_guid":"b2189b02-02af-49ae-89b0-a1581dd9e1f6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-26T08:56:05.684568Z","iopub.execute_input":"2025-05-26T08:56:05.684866Z","iopub.status.idle":"2025-05-26T08:56:51.348307Z","shell.execute_reply.started":"2025-05-26T08:56:05.684847Z","shell.execute_reply":"2025-05-26T08:56:51.346754Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Results & Analysis\nPlot results","metadata":{"_uuid":"a8c2cdba-2925-4713-9cf9-d6b0e995aa65","_cell_guid":"f3634002-548c-4f06-955e-6b85b5e203b5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nfor i, result in enumerate(results):\n    plt.subplot(2, 2, 1)\n    plt.plot(result['train_losses'], label=f\"Train Loss (Params {i+1})\")\n    plt.plot(result['val_losses'], label=f\"Val Loss (Params {i+1})\")\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.subplot(2, 2, 2)\n    plt.plot(result['val_accuracies'], label=f\"Val Accuracy (Params {i+1})\")\n    plt.title('Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.subplot(2, 2, 3)\n    plt.plot(result['val_aucs'], label=f\"Val AUC (Params {i+1})\")\n    plt.title('Validation AUC')\n    plt.xlabel('Epoch')\n    plt.ylabel('AUC')\n    plt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"59b68658-f94a-49f8-81c3-109973bfa957","_cell_guid":"5908eebe-8fc5-495e-b1e2-e2bec3483b61","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-26T08:45:51.962725Z","iopub.status.idle":"2025-05-26T08:45:51.963025Z","shell.execute_reply.started":"2025-05-26T08:45:51.962890Z","shell.execute_reply":"2025-05-26T08:45:51.962906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{"_uuid":"ec451cd5-0d2a-4294-8355-c1ac3d9bd903","_cell_guid":"d6764f17-1618-4619-9fa6-a5d924925d98","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Create submission file\nfrom torch.utils.data import DataLoader\n\nbest_result = max(results, key=lambda x: max(x['val_aucs']))  # Choose model with highest AUC\nbest_model_state = best_result['best_model']\nmodel = DeepCNN(num_filters=best_result['params']['num_filters'], \n                dropout_rate=best_result['params']['dropout_rate']).to(device)\nmodel.load_state_dict(best_model_state)\nmodel.eval()\n\ntest_df = pd.DataFrame({'id': [f.split('.tif')[0] for f in os.listdir(test_images_dir)]})\ntest_dataset = CancerDataset(test_df, test_images_dir, transform=val_transforms)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n\n# Make predictions\npredictions = []\nimage_ids = test_df['id'].values\n\nwith torch.no_grad():\n    for inputs, _ in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Probability of class 1\n        predictions.extend(probs)\n\nsubmission_df = pd.DataFrame({'id': image_ids, 'label': predictions})\n\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file 'submission.csv' created successfully!\")","metadata":{"_uuid":"104433fb-c2dc-4705-8011-c0b38f45ac7e","_cell_guid":"c952a33b-9584-480a-b54a-e13d08233561","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-26T08:45:51.964820Z","iopub.status.idle":"2025-05-26T08:45:51.965227Z","shell.execute_reply.started":"2025-05-26T08:45:51.965033Z","shell.execute_reply":"2025-05-26T08:45:51.965050Z"}},"outputs":[],"execution_count":null}]}